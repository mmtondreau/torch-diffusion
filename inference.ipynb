{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c24a0c6-9ed6-4d5b-94cf-94003748d65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_diffusion.model.difussion_model import DiffusionModule, DiffusionModuleConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "# from typing import Dict, Tuple\n",
    "# from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchvision import models, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e37bef44-d97b-4578-a653-65c090de7c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiffusionModule.load_from_checkpoint(\n",
    "            \"model_checkpoints/epoch=0-val_loss=0.15.ckpt\",\n",
    "            config=DiffusionModuleConfig(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af56aa96-c475-495d-8d83-df576bf58fd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'beta2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# construct DDPM noise schedule\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m b_t \u001b[38;5;241m=\u001b[39m (\u001b[43mbeta2\u001b[49m \u001b[38;5;241m-\u001b[39m beta1) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, timesteps \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;241m+\u001b[39m beta1\n\u001b[1;32m      3\u001b[0m a_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m b_t\n\u001b[1;32m      4\u001b[0m ab_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcumsum(a_t\u001b[38;5;241m.\u001b[39mlog(), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mexp()    \n",
      "\u001b[0;31mNameError\u001b[0m: name 'beta2' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62f5e203-262d-4766-abd1-14c54ad4717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "# diffusion hyperparameters\n",
    "timesteps = 500\n",
    "beta1 = 1e-4\n",
    "beta2 = 0.02\n",
    "\n",
    "# network hyperparameters\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else torch.device('cpu'))\n",
    "n_feat = 64 # 64 hidden dimension feature\n",
    "n_cfeat = 5 # context vector is of size 5\n",
    "height = 192 # 16x16 image\n",
    "width = 128\n",
    "save_dir = './weights/'\n",
    "\n",
    "# training hyperparameters\n",
    "batch_size = 100\n",
    "n_epoch = 32\n",
    "lrate=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68b1916d-2190-46f1-a191-43b6383fdc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct DDPM noise schedule\n",
    "b_t = (beta2 - beta1) * torch.linspace(0, 1, timesteps + 1, device=device) + beta1\n",
    "a_t = 1 - b_t\n",
    "ab_t = torch.cumsum(a_t.log(), dim=0).exp()    \n",
    "ab_t[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b1b555b-fc0d-4dcb-9189-63f1c514b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sampling function for DDIM   \n",
    "# removes the noise using ddim\n",
    "def denoise_ddim(x, t, t_prev, pred_noise):\n",
    "    ab = ab_t[t]\n",
    "    ab_prev = ab_t[t_prev]\n",
    "    \n",
    "    x0_pred = ab_prev.sqrt() / ab.sqrt() * (x - (1 - ab).sqrt() * pred_noise)\n",
    "    dir_xt = (1 - ab_prev).sqrt() * pred_noise\n",
    "\n",
    "    return x0_pred + dir_xt\n",
    "\n",
    "\n",
    "def unorm(x):\n",
    "    # unity norm. results in range of [0,1]\n",
    "    # assume x (h,w,3)\n",
    "    xmax = x.max((0,1))\n",
    "    xmin = x.min((0,1))\n",
    "    return(x - xmin)/(xmax - xmin)\n",
    "\n",
    "def norm_all(store, n_t, n_s):\n",
    "    # runs unity norm on all timesteps of all samples\n",
    "    nstore = np.zeros_like(store)\n",
    "    for t in range(n_t):\n",
    "        for s in range(n_s):\n",
    "            nstore[t,s] = unorm(store[t,s])\n",
    "    return nstore\n",
    "\n",
    "def norm_torch(x_all):\n",
    "    # runs unity norm on all timesteps of all samples\n",
    "    # input is (n_samples, 3,h,w), the torch image format\n",
    "    x = x_all.cpu().numpy()\n",
    "    xmax = x.max((2,3))\n",
    "    xmin = x.min((2,3))\n",
    "    xmax = np.expand_dims(xmax,(2,3)) \n",
    "    xmin = np.expand_dims(xmin,(2,3))\n",
    "    nstore = (x - xmin)/(xmax - xmin)\n",
    "    return torch.from_numpy(nstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7f47b67-b9c4-40e1-8d62-217a5a67c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample quickly using DDIM\n",
    "@torch.no_grad()\n",
    "def sample_ddim(n_sample, n=20):\n",
    "    # x_T ~ N(0, 1), sample initial noise\n",
    "    samples = torch.randn(n_sample, 3, height, width).to(device)  \n",
    "\n",
    "    # array to keep track of generated steps for plotting\n",
    "    intermediate = [] \n",
    "    step_size = timesteps // n\n",
    "    for i in range(timesteps, 0, -step_size):\n",
    "        print(f'sampling timestep {i:3d}', end='\\r')\n",
    "\n",
    "        # reshape time tensor\n",
    "        t = torch.tensor([i / timesteps])[:, None, None, None].to(device)\n",
    "\n",
    "        eps = model(samples, t)    # predict noise e_(x_t,t)\n",
    "        samples = denoise_ddim(samples, i, i - step_size, eps)\n",
    "        intermediate.append(samples.detach().cpu().numpy())\n",
    "\n",
    "    intermediate = np.stack(intermediate)\n",
    "    return samples, intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d6d5db2-22aa-471d-beb2-aee16a47dd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function; removes the predicted noise (but adds some noise back in to avoid collapse)\n",
    "def denoise_add_noise(x, t, pred_noise, z=None):\n",
    "    if z is None:\n",
    "        z = torch.randn_like(x)\n",
    "    noise = b_t.sqrt()[t] * z\n",
    "    mean = (x - pred_noise * ((1 - a_t[t]) / (1 - ab_t[t]).sqrt())) / a_t[t].sqrt()\n",
    "    return mean + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "555bb70f-8f25-477a-9793-e0a5f202a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample using standard algorithm\n",
    "@torch.no_grad()\n",
    "def sample_ddpm(n_sample, save_rate=20):\n",
    "    # x_T ~ N(0, 1), sample initial noise\n",
    "    samples = torch.randn(n_sample, 3, height, width).to(device)  \n",
    "\n",
    "    # array to keep track of generated steps for plotting\n",
    "    intermediate = [] \n",
    "    for i in range(timesteps, 0, -1):\n",
    "        print(f'sampling timestep {i:3d}', end='\\r')\n",
    "\n",
    "        # reshape time tensor\n",
    "        t = torch.tensor([i / timesteps])[:, None, None, None].to(device)\n",
    "\n",
    "        # sample some random noise to inject back in. For i = 1, don't add back in noise\n",
    "        z = torch.randn_like(samples) if i > 1 else 0\n",
    "\n",
    "        eps = model(samples, t)    # predict noise e_(x_t,t)\n",
    "        samples = denoise_add_noise(samples, i, eps, z)\n",
    "        if i % save_rate ==0 or i==timesteps or i<8:\n",
    "            intermediate.append(samples.detach().cpu().numpy())\n",
    "\n",
    "    intermediate = np.stack(intermediate)\n",
    "    return samples, intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14269cd0-2bbd-4fd7-8411-8919f052208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid(x,n_sample,n_rows,save_dir,w):\n",
    "    # x:(n_sample, 3, h, w)\n",
    "    ncols = n_sample//n_rows\n",
    "    grid = make_grid(norm_torch(x), nrow=ncols)  # curiously, nrow is number of columns.. or number of items in the row.\n",
    "    save_image(grid, save_dir + f\"run_image_w{w}.png\")\n",
    "    print('saved image at ' + save_dir + f\"run_image_w{w}.png\")\n",
    "    return grid\n",
    "\n",
    "def plot_sample(x_gen_store,n_sample,nrows,save_dir, fn,  w, save=False):\n",
    "    ncols = n_sample//nrows\n",
    "    sx_gen_store = np.moveaxis(x_gen_store,2,4)                               # change to Numpy image format (h,w,channels) vs (channels,h,w)\n",
    "    nsx_gen_store = norm_all(sx_gen_store, sx_gen_store.shape[0], n_sample)   # unity norm to put in range [0,1] for np.imshow\n",
    "    \n",
    "    # create gif of images evolving over time, based on x_gen_store\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey=True,figsize=(ncols,nrows))\n",
    "    def animate_diff(i, store):\n",
    "        print(f'gif animating frame {i} of {store.shape[0]}', end='\\r')\n",
    "        plots = []\n",
    "        for row in range(nrows):\n",
    "            for col in range(ncols):\n",
    "                axs[row, col].clear()\n",
    "                axs[row, col].set_xticks([])\n",
    "                axs[row, col].set_yticks([])\n",
    "                plots.append(axs[row, col].imshow(store[i,(row*ncols)+col]))\n",
    "        return plots\n",
    "    ani = FuncAnimation(fig, animate_diff, fargs=[nsx_gen_store],  interval=200, blit=False, repeat=True, frames=nsx_gen_store.shape[0]) \n",
    "    plt.close()\n",
    "    if save:\n",
    "        ani.save(save_dir + f\"{fn}_w{w}.gif\", dpi=100, writer=PillowWriter(fps=5))\n",
    "        print('saved gif at ' + save_dir + f\"{fn}_w{w}.gif\")\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a8cc0d-354f-408c-9989-272ad55c66c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0a79448-a48b-464b-ad6a-f494a797c9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize samples\n",
    "# plt.clf()\n",
    "# samples, intermediate = sample_ddim(5, n=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc0933e2-a4c9-4217-9d1e-b67e3c77cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# animation_ddim = plot_sample(intermediate,32,4,save_dir, \"ani_run\", None, save=False)\n",
    "# HTML(animation_ddim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf86793-987f-457e-b9a7-df70f0268e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling timestep  11\r"
     ]
    }
   ],
   "source": [
    "plt.clf()\n",
    "samples, intermediate = sample_ddpm(32, save_rate=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92a2036-23fb-46df-aa02-a4b44a32b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation_ddim = plot_sample(intermediate,5,4,save_dir, \"ani_run\", None, save=False)\n",
    "HTML(animation_ddim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8afac-78e2-4d40-bc3b-83fedc0f95e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5774011c-1962-4a58-8818-c11b51860196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6d26b2-6b2f-440b-bf5e-8883c9fbb23f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d39b1-243e-4e17-97e2-d60ba08b428e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
